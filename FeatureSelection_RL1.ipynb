{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.data)\n",
    "Y = pd.DataFrame(data.target)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(input):\n",
    "    x_train = X_train[input]\n",
    "    x_test = X_test[input]\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    clf.fit(x_train, y_train.values.ravel())\n",
    "    f1_score = clf.score(x_test, y_test)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q_values = [[-1,-1]]*30\n",
    "Q_value=-np.ones([30, 2], dtype = int)\n",
    "ActionTable = np.ones([30, 2], dtype = int)\n",
    "for i in range(30):\n",
    "    ActionTable[i][0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(features):\n",
    "    if len(features)==0:\n",
    "        return 0\n",
    "    acc = accuracy(features)*100\n",
    "    tot_f = len(features)\n",
    "    R = acc\n",
    "    if tot_f>K:\n",
    "        R = acc*K/tot_f\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.15\n",
    "alpha = 0.2\n",
    "epsilon_decay_rate = 0.9995\n",
    "alpha_decay_rate = 0.9995\n",
    "K = 2\n",
    "all_rewards = []\n",
    "num_episodes = 100\n",
    "num_agents = 30\n",
    "reward_store={}\n",
    "flag_CLEAN=1\n",
    "for i in range(31):\n",
    "    reward_store[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_greedyAction(Q_value,ActionTable,agent):\n",
    "    actionIndex = np.argmax(Q_value[agent])   # index of maximum Q-value\n",
    "    return actionIndex\n",
    "    #action = ActionTable[agent][actionIndex]\n",
    "    #return action\n",
    "    \n",
    "# Random exploration strategy\n",
    "def online_randomAction(Q_value,ActionTable,agent):\n",
    "    actionIndex = random.randrange(0,2)\n",
    "    return actionIndex\n",
    "    #action = ActionTable[agent][actionIndex]\n",
    "    #return action\n",
    "\n",
    "# Epsilon-greedy exploration strategy\n",
    "def offline_eGreedy(Q_value,ActionTable,agent,epsilon):\n",
    "    # Choose action\n",
    "    temp = np.argmax(Q_value[agent])   # index of maximum Q-value\n",
    "\n",
    "    rand = random.uniform(0,1)\n",
    "    if rand > epsilon:\n",
    "        # Choose greedy action\n",
    "        counterfactualIndex = temp\n",
    "    else:\n",
    "        # Choose random action\n",
    "        counterfactualIndex = random.randrange(0,2)\n",
    "        while counterfactualIndex == temp:\n",
    "            counterfactualIndex = random.randrange(0,2)\n",
    "\n",
    "    return counterfactualIndex\n",
    "    #counterfactual = ActionTable[agent][counterfactualIndex]\n",
    "    #return counterfactual\n",
    "\n",
    "# Random exploration strategy\n",
    "def offline_randomAction(Q_value,ActionTable,agent):\n",
    "    counterfactualIndex = random.randrange(0,2)\n",
    "    return counterfactualIndex\n",
    "    #counterfactual = ActionTable[agent][counterfactualIndex]\n",
    "    #return counterfactual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "[2, 8, 14, 18]\n",
      "43.859649122807014\n",
      "[2, 14, 18]\n",
      "58.47953216374268\n",
      "[2, 14, 18]\n",
      "58.47953216374268\n",
      "[2, 18]\n",
      "87.71929824561403\n",
      "[2, 18]\n",
      "87.71929824561403\n",
      "[2, 18]\n",
      "87.71929824561403\n",
      "[2, 18]\n",
      "87.71929824561403\n",
      "[2, 18]\n",
      "87.71929824561403\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[18]\n",
      "63.1578947368421\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "actions = [0] *num_agents\n",
    "for episode in range(num_episodes):\n",
    "    for agent in range(num_agents):\n",
    "        if flag_CLEAN ==1:\n",
    "            action = online_greedyAction(Q_value,ActionTable,agent)\n",
    "        else:\n",
    "            action = online_randomAction(Q_value,ActionTable,agent)\n",
    "        actions[agent]=action\n",
    "    features = []\n",
    "    for i, act in enumerate(actions):\n",
    "        if act == 1:\n",
    "            features.append(i)\n",
    "    #print(features)\n",
    "    R = get_reward(features)\n",
    "    #print(R)\n",
    "    reward_store[len(features)]=max(reward_store[len(features)],R)\n",
    "    for agent in range(num_agents):\n",
    "        if flag_CLEAN ==1:\n",
    "            counterfactual = offline_eGreedy(Q_value,ActionTable,agent,epsilon)\n",
    "            actions[counterfactual]=action\n",
    "            features = []\n",
    "            for i, act in enumerate(actions):\n",
    "                if act == 1:\n",
    "                    features.append(i)\n",
    "            C_agent = get_reward(features) - R\n",
    "            Q_value[agent][counterfactual] = Q_value[agent][counterfactual]+ alpha * (C_agent - Q_value[agent][counterfactual])\n",
    "        else:\n",
    "            action = online_randomAction(Q_value,ActionTable,agent)\n",
    "            Q_value[agent][action] = Q_value[agent][action]+ alpha * (R - Q_value[agent][action])\n",
    "    alpha = alpha * alpha_decay_rate\n",
    "    epsilon = epsilon * epsilon_decay_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actions = [0] *num_agents\n",
    "for episode in range(num_episodes):\n",
    "        for agent in range(num_agents):\n",
    "                rand_number = random.uniform(0,1)\n",
    "                if rand_number>epsilon:\n",
    "                    #actions[agent]  = Q_values[agent].index(max(Q_values[agent]))\n",
    "                    actions[agent] = np.argmax(Q_values[agent])\n",
    "                else:\n",
    "                    actions[agent] = random.choice([0,1])\n",
    "        features = []\n",
    "        for i, act in enumerate(actions):\n",
    "            if act == 1:\n",
    "                features.append(i)\n",
    "        #print(features)\n",
    "        R = get_reward(features)\n",
    "        reward_store[len(features)]=max(reward_store[len(features)],R)\n",
    "        #print(R)\n",
    "        all_rewards.append(R)\n",
    "        for agent in range (num_agents):\n",
    "                actions[agent] = 1-actions[agent]\n",
    "                features = []\n",
    "                for i, act in enumerate(actions):\n",
    "                    if act == 1:\n",
    "                        features.append(i)\n",
    "                C_agent = get_reward(features) - R\n",
    "                Q_values[agent][actions[agent]] = Q_values[agent][actions[agent]] + alpha*(C_agent - Q_values[agent][actions[agent]])\n",
    "        alpha = alpha * alpha_decay_rate\n",
    "        epsilon = epsilon * epsilon_decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0 -1]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]]\n",
      "{0: 0, 1: 65.78947368421053, 2: 0, 3: 60.23391812865498, 4: 44.73684210526316, 5: 0, 6: 29.82456140350877, 7: 0, 8: 23.026315789473685, 9: 20.662768031189085, 10: 0, 11: 0, 12: 0, 13: 13.765182186234817, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0}\n"
     ]
    }
   ],
   "source": [
    "print(reward_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
